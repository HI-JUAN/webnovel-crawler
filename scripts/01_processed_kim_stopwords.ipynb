{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9771d82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  댓글\n",
      "0                                          비서 그렇다 장판\n",
      "1                           회장 그냥 미소 며느리 삼고 싶다 말씀 하다\n",
      "2  동생 관심 쏠리다 질투 하다 동생 벌다 진일 벌어지다 일로 착각 하다 된거 동생 경...\n",
      "3                         배다 웃기 죽겠네 그동안 보지 하다 캐릭터 남다\n",
      "4                           원래 오빠 하다 괜찮다 오빠 하다 꼴다 보다\n"
     ]
    }
   ],
   "source": [
    "# 내가 생각하는 최종ver.불용어 제거(이모티콘 축약)\n",
    "import pandas as pd\n",
    "import stopwordsiso as stopwords\n",
    "from konlpy.tag import Okt\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "\n",
    "# 1) CSV 로드\n",
    "df = pd.read_csv('/Users/leejuan/Documents/GitHub/webnovel-crawler/data/raw/[알수없는회차]_댓글_20250617_181947.csv')\n",
    "\n",
    "# 2) 불용어 집합 정의\n",
    "base_stopwords = stopwords.stopwords(\"ko\")\n",
    "domain_stopwords = {\n",
    "    \"화수\", \"회차\",\n",
    "    \"미리보기\", \"무료\",\n",
    "    \"<div>\", \"</div>\", \"<br>\", \"&nbsp;\",\n",
    "    \"href\", \"class\", \"id\", \"onclick\",\n",
    "    \"댓글\", \"작성\", \"작성자\", \"조회\", \"추천\", \"공감\",\n",
    "    \"작가님\", \"작가\", \"작품\", \"내용\", \"부분\"\n",
    "}\n",
    "custom_stopwords = base_stopwords.union(domain_stopwords)\n",
    "\n",
    "# 3) 이모티콘 패턴 정의 (연속된 동일 자모가 이모티콘)\n",
    "emoticon_pattern = re.compile(r'^(?:[ㅋㅎㅠㅜ])+$')\n",
    "\n",
    "# 4) 이모티콘 정규화 함수: 중복된 문자를 한 글자로 축소\n",
    "def normalize_emoticon(tok: str) -> str:\n",
    "    # 반복된 ㅋ, ㅎ, ㅠ, ㅜ 글자 중 첫 글자만 남김\n",
    "    return re.sub(r'([ㅋㅎㅠㅜ])\\1+', r'\\1', tok)\n",
    "\n",
    "def is_emoticon(tok: str) -> bool:\n",
    "    return bool(emoticon_pattern.fullmatch(tok))\n",
    "\n",
    "# 5) 형태소 분석기 초기화\n",
    "okt = Okt()\n",
    "\n",
    "# 6) 전처리 함수\n",
    "def preprocess(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    # HTML 태그 제거\n",
    "    text = re.sub(r'<[^>]+>', ' ', text)\n",
    "    # 형태소 단위 토큰화 및 어간 추출\n",
    "    tokens = okt.morphs(text, stem=True)\n",
    "\n",
    "    filtered = []\n",
    "    for tok in tokens:\n",
    "        # 이모티콘은 정규화하여 보존\n",
    "        if is_emoticon(tok):\n",
    "            filtered.append(normalize_emoticon(tok))\n",
    "            continue\n",
    "        # 불용어 제거\n",
    "        if tok in custom_stopwords:\n",
    "            continue\n",
    "        # 너무 짧은 토큰 제거\n",
    "        if len(tok) <= 1:\n",
    "            continue\n",
    "        filtered.append(tok)\n",
    "\n",
    "    return \" \".join(filtered)\n",
    "\n",
    "# 7) df['댓글'] 컬럼에 적용\n",
    "df['댓글'] = df['댓글'].fillna('').apply(preprocess)\n",
    "\n",
    "def extract_nav(text: str) -> str:\n",
    "    # norm=True: 발화체 정규화, stem=True: 어간 추출\n",
    "    pos_tags = okt.pos(text, norm=True, stem=True)\n",
    "    # 명사, 형용사, 동사 품사만 필터링\n",
    "    filtered = [word for word, pos in pos_tags if pos in ('Noun', 'Adjective', 'Verb')]\n",
    "    # (선택) 너무 짧은 토큰 제거\n",
    "    filtered = [tok for tok in filtered if len(tok) > 1]\n",
    "    return \" \".join(filtered)\n",
    "\n",
    "# 새로운 컬럼에 적용\n",
    "df['댓글'] = df['댓글'].apply(extract_nav)\n",
    "\n",
    "\n",
    "# 8) 결과 확인\n",
    "print(df[['댓글']].head())\n",
    "\n",
    "# 9) (선택) 전처리된 데이터 저장 (processed_nahonja_levelup_cleaned.csv)\n",
    "df.to_csv('/Users/leejuan/Documents/GitHub/webnovel-crawler/data/processed/kim_processed_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "693dc592",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'base_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 50\u001b[39m\n\u001b[32m     46\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mNeutral\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# 6. CSV 불러오기 및 분석 적용\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m df = pd.read_csv(os.path.join(\u001b[43mbase_dir\u001b[49m, \u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mprocessed\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mkim_processed_1.csv\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m     52\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33m감정_라벨\u001b[39m\u001b[33m'\u001b[39m] = df[\u001b[33m'\u001b[39m\u001b[33m댓글\u001b[39m\u001b[33m'\u001b[39m].apply(rule_sentiment)\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# 7. 결과 저장\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'base_dir' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from konlpy.tag import Okt\n",
    "import re\n",
    "\n",
    "# 1. 사전 불러오기 함수\n",
    "def load_word_list(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        return set(line.strip() for line in f if line.strip())\n",
    "\n",
    "\n",
    "# 2. 경로 설정\n",
    "\n",
    "pos_path = '/Users/leejuan/Documents/GitHub/webnovel-crawler/scripts/pos_words.txt'\n",
    "neg_path = '/Users/leejuan/Documents/GitHub/webnovel-crawler/scripts/neg_words.txt'\n",
    "pos_words = load_word_list(pos_path)\n",
    "neg_words = load_word_list(neg_path)\n",
    "\n",
    "\n",
    "# 3. 형태소 분석기 초기화\n",
    "okt = Okt()\n",
    "\n",
    "\n",
    "# 4. 텍스트 전처리 함수\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = re.sub(r'<[^>]+>', ' ', text)         # HTML 태그 제거\n",
    "    text = re.sub(r'[^가-힣\\s]', ' ', text)       # 특수문자 제거\n",
    "    return text\n",
    "\n",
    "\n",
    "# 5. 감정 분석 함수\n",
    "def rule_sentiment(text: str) -> str:\n",
    "    text = clean_text(text)\n",
    "    tokens = okt.morphs(text, stem=True)\n",
    "\n",
    "    pos_score = sum(1 for t in tokens if t in pos_words)\n",
    "    neg_score = sum(1 for t in tokens if t in neg_words)\n",
    "\n",
    "    if pos_score > neg_score:\n",
    "        return \"Positive\"\n",
    "    elif neg_score > pos_score:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "\n",
    "# 6. CSV 불러오기 및 분석 적용\n",
    "df = pd.read_csv(os.path.join(base_dir, 'data', 'processed', 'kim_processed_1.csv'))\n",
    "\n",
    "df['감정_라벨'] = df['댓글'].apply(rule_sentiment)\n",
    "\n",
    "\n",
    "# 7. 결과 저장\n",
    "base_dir = '/Users/leejuan/Documents/GitHub/webnovel-crawler'\n",
    "df.to_csv(os.path.join(base_dir, 'data', 'processed', 'kim_processed_final.csv'), index=False, encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "# 8. 통계 확인\n",
    "\n",
    "print(df[['댓글', '감정_라벨']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ea62826c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "감정_라벨\n",
       "Neutral     4441\n",
       "Positive    3759\n",
       "Negative    1801\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['감정_라벨'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8334d4ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3facb77a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5d27b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d2a772",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a364ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a191f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c95c382",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
